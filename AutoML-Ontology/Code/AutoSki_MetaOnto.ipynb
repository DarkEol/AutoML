{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFTIWiU7EOyIr/LV52EQ1N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarkEol/AutoML/blob/main/AutoML-Ontology/Code/AutoSki_MetaOnto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##script for model search by AutoSklearn constrained with ontology"
      ],
      "metadata": {
        "id": "OVay-hHvfxJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#downgrade to install auto-sklearn\n",
        "!pip install Cython==0.29.36\n",
        "!pip uninstall scipy -y\n",
        "!pip install scipy==1.9\n",
        "!pip uninstall pyparsing -y\n",
        "!pip install pyparsing==2.4"
      ],
      "metadata": {
        "id": "T-uJ-HGBNEp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3cpaR0uY_WY"
      },
      "outputs": [],
      "source": [
        "!pip uninstall scikit_learn -y\n",
        "!pip install scikit-learn==0.24.2 --no-build-isolation\n",
        "!pip install auto-sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install owlready2"
      ],
      "metadata": {
        "id": "L0cQFNovaToe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making imports\n",
        "from __future__ import annotations\n",
        "import autosklearn.classification\n",
        "import sklearn.model_selection\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import pickle\n",
        "#import graphviz\n",
        "from sklearn import tree\n",
        "from owlready2 import *\n",
        "from sklearn.datasets import fetch_openml\n",
        "#from sklearn.datasets import load_iris\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.tree import export_text\n",
        "from sklearn import preprocessing\n",
        "from smac.optimizer.smbo import SMBO\n",
        "from smac.runhistory.runhistory import RunInfo, RunValue\n",
        "from autosklearn.metrics import balanced_accuracy, precision, recall, f1\n",
        "import time"
      ],
      "metadata": {
        "id": "Kf2uNPVZagkU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define function for early stopping\n",
        "cost_lim = 0.10   #value of cost for early stopping\n",
        "def callback(\n",
        "    smbo: SMBO,\n",
        "    run_info: RunInfo,\n",
        "    result: RunValue,\n",
        "    time_left: float,\n",
        ") -> bool | None:\n",
        "    \"\"\"Stop early if we get a very low cost value for a single run\n",
        "\n",
        "    The return value indicates to SMAC whether to stop or not. False will\n",
        "    stop the search process while any other value will mean it continues.\n",
        "    \"\"\"\n",
        "    # You can find out the parameters in the SMAC documentation\n",
        "    # https://automl.github.io/SMAC3/main/\n",
        "    if result.cost <= cost_lim:\n",
        "        print(\"Stopping!\")\n",
        "        print(run_info)\n",
        "        print(result)\n",
        "        return False"
      ],
      "metadata": {
        "id": "gTkDMkvCak7t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define list of algorithms\n",
        "full_set = ['adaboost', 'bernoulli_nb', 'decision_tree', 'extra_trees', 'gaussian_nb', 'gradient_boosting',\n",
        "            'k_nearest_neighbors', 'lda', 'liblinear_svc', 'libsvm_svc', 'mlp', 'multinomial_nb',\n",
        "            'passive_aggressive', 'qda', 'random_forest', 'sgd']\n",
        "\n",
        "dict_algos = {'AdaBoostClassifier': 'adaboost',\n",
        "              'ExtraTreesClassifier': 'extra_trees',\n",
        "              'GradientBoostingClassifier': 'gradient_boosting',\n",
        "              'KNeighborsClassifier': 'k_nearest_neighbors',\n",
        "              'PassiveAggressiveClassifier': 'passive_aggressive',\n",
        "              'LIN_SVC': 'liblinear_svc',\n",
        "              'MLPClassifier': 'mlp',\n",
        "              'RandomForestClassifier': 'random_forest',\n",
        "              'SVM_SVC':'libsvm_svc'}\n",
        "\n",
        "onto = get_ontology(\"OntologyEmpty.owl\").load()\n",
        "\n",
        "dict_features = {\n",
        "    'BinaryClass' : onto.BinaryClass,\n",
        "    'NoBinaryClass' : onto.NoBinaryClass,\n",
        "    'StringClass' : onto.StringClass,\n",
        "    'NoStringClass' : onto.NoStringClass,\n",
        "    'UnaryAttibutes' : onto.UnaryAttibutes,\n",
        "    'NoUnaryAttibutes' : onto.NoUnaryAttibutes,\n",
        "    'ManyFeatures' : onto.ManyFeatures,\n",
        "    'FewFeatures' : onto.FewFeatures,\n",
        "    'NoManyFeatures' : onto.FewFeatures,\n",
        "    'NoFewFeatures' : onto.ManyFeatures,\n",
        "    'ManyInstances' : onto.ManyInstances,\n",
        "    'FewInstances' : onto.FewInstances,\n",
        "    'NoManyInstances' : onto.FewInstances,\n",
        "    'NoFewInstances' : onto.ManyInstances,\n",
        "    'BinaryAttributes' : onto.BinaryAttributes,\n",
        "    'NoBinaryAttributes' : onto.NoBinaryAttributes,\n",
        "    'NumericAttributes' : onto.NumericAttributes,\n",
        "    'NoNumericAttributes' : onto.NoNumericAttributes,\n",
        "    'NominalAttributes' : onto.NominalAttributes,\n",
        "    'NoNominalAttributes' : onto.NoNominalAttributes,\n",
        "    'StringAttributes' : onto.StringAttributes,\n",
        "    'NoStringAttributes' : onto.NoStringAttributes,\n",
        "    'MissingValues' : onto.MissingValues,\n",
        "    'NoMissingValues' : onto.NoMissingValues,\n",
        "    'NumericClass' : onto.NumericClass,\n",
        "    'NoNumericClass' : onto.NoNumericClass\n",
        "    }\n",
        "\n",
        "results = pd.DataFrame(columns=[\"Dataset\", \"AutoML library\",\t\"Limit\",\t\"Num. DataSets\", \"Data characteristic\",\t\"Selected algorithm\",\t\"Accuracy\", \"Precision\", \"Recall\", \"F-measure\",\t\"AUC\", \"Time elapsed\"])"
      ],
      "metadata": {
        "id": "N0Ly0pOlbHbV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for quering ontology with specific meta-feature\n",
        "def queryOntology(num, data_char):\n",
        "  ontologyName = \"ontology-\"+str(num)+\"-as.owl\"\n",
        "  onto = get_ontology(ontologyName).load()\n",
        "\n",
        "  # querying ontology\n",
        "  list_algos = list()\n",
        "  for cls in list(onto.AutoSklearnAlgorithm.subclasses()):\n",
        "    if (dict_features[data_char] in cls.suitableFor):\n",
        "      list_algos.append(dict_algos[cls.name])\n",
        "  list_algos=list(set(list_algos)) #get unique values\n",
        "  return list_algos"
      ],
      "metadata": {
        "id": "oa4w2T2xhh8M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#firstly all features are false\n",
        "features = pd.Series(data=[False] * 24, index=['ManyInstances', 'FewInstances', 'ManyFeatures', 'FewFeatures',\n",
        "       'BinaryClass', 'DateClass', 'MissingClassValues', 'NominalClass',\n",
        "       'NumericClass', 'NoClass', 'UnaryClass', 'EmptyNominalClass',\n",
        "       'StringClass', 'RelationalClass', 'OnlyMulti-InstanceData',\n",
        "       'BinaryAttributes', 'DateAttributes', 'EmptyNominalAttributes',\n",
        "       'MissingValues', 'NominalAttributes', 'NumericAttributes',\n",
        "       'UnaryAttibutes', 'RelationalAttributes', 'StringAttributes'])\n",
        "\n",
        "#load dataset from OpenML by ID\n",
        "opml = fetch_openml(data_id=1461)\n",
        "data = opml.data\n",
        "X = opml.data\n",
        "y = opml.target\n",
        "\n",
        "name = opml.details['name']\n",
        "\n",
        "shape = X.shape\n",
        "n_instances = shape[0]\n",
        "n_features = shape[1]\n",
        "n_target_values = len(y.unique())\n",
        "numeric_data = X.select_dtypes(include=[np.number])\n",
        "not_numeric_data = X.select_dtypes(exclude=[np.number])\n",
        "category_data = X.select_dtypes(include=['category'])\n",
        "\n",
        "if n_target_values == 2:\n",
        "  binary_class = True\n",
        "  features['BinaryClass'] = True\n",
        "  print(\"Binary\")\n",
        "else:\n",
        "  binary_class = False\n",
        "  print(\"MultiClass\")\n",
        "\n",
        "if y.str.isnumeric().any():\n",
        "  features['NumericClass'] = True\n",
        "  string_class = False\n",
        "  print(\"No string class\")\n",
        "else:\n",
        "  string_class = True\n",
        "  features['StringClass'] = True\n",
        "  print(\"String class\")\n",
        "\n",
        "if n_instances > 3200:\n",
        "  many_instances = True\n",
        "  features['ManyInstances'] = True\n",
        "  print(\"Many instances\")\n",
        "else:\n",
        "  many_instances = False\n",
        "  features['FewInstances'] = True\n",
        "  print(\"Few instances\")\n",
        "\n",
        "if n_features > 100:\n",
        "  print(\"Many features\")\n",
        "else:\n",
        "  features['FewFeatures'] = True\n",
        "  print(\"Few features\")\n",
        "\n",
        "if numeric_data.shape[1] > 0:\n",
        "  features['NumericAttributes'] = True\n",
        "\n",
        "if category_data.shape[1] > 0:\n",
        "  features['NominalAttributes'] = True\n",
        "\n",
        "binary_attributes = False\n",
        "string_attributes = False\n",
        "missing_values = False\n",
        "\n",
        "for fname in opml.feature_names:\n",
        "  if len(X[fname].unique())==2: # and not binary_attributes:\n",
        "    binary_attributes = True\n",
        "    features['BinaryAttributes'] = True\n",
        "\n",
        "  if len(X[fname].unique())==1:\n",
        "    features['UnaryAttributes'] = True\n",
        "\n",
        "  if X[fname].isna().sum() > 0:\n",
        "    missing_values = True\n",
        "    features['MissingValues'] = True\n",
        "\n",
        "  if not pd.api.types.is_numeric_dtype(X[fname]):\n",
        "    string_attributes = True\n",
        "    features['StringAttributes'] = True\n",
        "\n",
        "if binary_attributes:\n",
        "  print(\"Binary attributes\")\n",
        "else:\n",
        "  print(\"No binary attributes\")\n",
        "if missing_values:\n",
        "  print(\"Missing values\")\n",
        "else:\n",
        "  print(\"No missing values\")\n",
        "if string_attributes:\n",
        "  print(\"String attributes\")\n",
        "else:\n",
        "  print(\"No string attributes\")\n",
        "\n",
        "if y.dtype=='category':\n",
        "  features['NominalClass'] = True\n",
        "  print(\"categorial class encoding\")\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  y = le.fit_transform(y)\n",
        "else:\n",
        "  print(\"not categorial class\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.20, random_state=1)"
      ],
      "metadata": {
        "id": "pqGjF7lbbPul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_ds = 35     #number of datasets used fore ontology creation (35 or 50)\n",
        "runtime = 900   #amount of time allocated for the search (in seconds)\n",
        "d_char = \"StringAttributes\" #attribute to search into ontology. take value from results of the previous cell\n",
        "\n",
        "#running search for best model\n",
        "if __name__ == '__main__':\n",
        "  for i in range(5):\n",
        "    # 0 - search with time constraint\n",
        "    # 1 - search with time constraint and early stopping\n",
        "    # >1 - search with time constraint, early stopping and use of ontology\n",
        "\n",
        "    start_time = time.time()\n",
        "    num = results.shape[0]\n",
        "    data_char = \"No characteristics\"\n",
        "    limits = \"cost <= \" + str(cost_lim)\n",
        "\n",
        "    #AutoML settings\n",
        "    if i==0:\n",
        "      limits = \"No limits\"\n",
        "      cls = autosklearn.classification.AutoSklearnClassifier(\n",
        "      ensemble_class=None,\n",
        "      time_left_for_this_task=runtime)\n",
        "\n",
        "    if i==1:\n",
        "      cls = autosklearn.classification.AutoSklearnClassifier(\n",
        "      get_trials_callback=callback,\n",
        "      ensemble_class=None,\n",
        "      time_left_for_this_task=runtime)\n",
        "\n",
        "    if i>1:\n",
        "      results.at[num, \"Num. DataSets\"] = num_ds\n",
        "      data_char = d_char\n",
        "      list_algos = queryOntology(num_ds, data_char)\n",
        "      print(list_algos)\n",
        "      cls = autosklearn.classification.AutoSklearnClassifier(\n",
        "      include={'classifier': list_algos},\n",
        "      get_trials_callback=callback,\n",
        "      ensemble_class=None,\n",
        "      time_left_for_this_task=runtime)\n",
        "\n",
        "    print(\"searching for model\")\n",
        "    cls.fit(X_train, y_train)\n",
        "    print(\"model found\")\n",
        "    elapsed = time.time() - start_time\n",
        "    print(\"elapsed: \", elapsed)\n",
        "\n",
        "    #info about found models\n",
        "    print(\"leaderboard\")\n",
        "    print(cls.leaderboard())\n",
        "\n",
        "    algo = cls.leaderboard().iat[0,2]\n",
        "\n",
        "    #predictions and multiclass metrics\n",
        "    predictions = cls.predict(X_test)\n",
        "    accuracy = cls.score(X_test, y_test)\n",
        "    if binary_class:\n",
        "      precision = sklearn.metrics.precision_score(y_test, predictions)\n",
        "      recall = sklearn.metrics.recall_score(y_test, predictions)\n",
        "      f1 = sklearn.metrics.f1_score(y_test, predictions)\n",
        "      auc = sklearn.metrics.roc_auc_score(y_test, predictions)\n",
        "    else:\n",
        "      precision = sklearn.metrics.precision_score(y_test, predictions, average='macro', zero_division=0) #macro for multiclass\n",
        "      recall = sklearn.metrics.recall_score(y_test, predictions, average='macro') #macro for multiclass\n",
        "      f1 = sklearn.metrics.f1_score(y_test, predictions, average='macro')\n",
        "      pred_proba = cls.predict_proba(X_test)  # for muliclass tasks\n",
        "      auc = sklearn.metrics.roc_auc_score(y_test, pred_proba, multi_class='ovr') #pred_proba for multiclass\n",
        "\n",
        "    print(\"algo: \",algo)\n",
        "    print(\"Accuracy\", accuracy)\n",
        "    print(\"Precision\", precision)\n",
        "    print(\"Recall\", recall)\n",
        "    print(\"F-measure\", f1)\n",
        "    print(\"AUC\", auc)\n",
        "\n",
        "    results.at[num,'Dataset'] = name\n",
        "    results.at[num,'AutoML library'] = \"Auto-Sklearn\"\n",
        "    results.at[num,'Limit'] = limits\n",
        "    results.at[num,'Data characteristic'] = data_char\n",
        "    results.at[num,'Algorithm'] = algo\n",
        "    results.at[num,'Accuracy'] = accuracy\n",
        "    results.at[num,'Precision'] = precision\n",
        "    results.at[num,'Recall'] = recall\n",
        "    results.at[num,'F-measure'] = f1\n",
        "    results.at[num,'AUC'] = auc\n",
        "    results.at[num,'Time elapsed'] = elapsed"
      ],
      "metadata": {
        "id": "BQ2xyGdVqLH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results.shape)\n",
        "print(results[['Dataset', 'Num. DataSets', 'Limit', 'Data characteristic', 'Algorithm', 'Accuracy', 'Time elapsed']])\n",
        "results.to_excel('Experiments-as.xlsx')"
      ],
      "metadata": {
        "id": "hkxk-5KpAeH_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
