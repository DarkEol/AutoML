{
  "nbformat": 4,
  "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarkEol/AutoML/blob/main/AutoML-Ontology/Code/AutoH2O_MetaOnto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Script for model search by H2O AutoML constrained with ontology"
      ],
      "metadata": {
        "id": "3g8r0ec3BfYC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEBEDgSbx-6L"
      },
      "outputs": [],
      "source": [
        "!pip install h2o"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install owlready2"
      ],
      "metadata": {
        "id": "2xRk2D1NzQa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import h2o\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from owlready2 import *\n",
        "from h2o.automl import H2OAutoML\n",
        "import sklearn.metrics\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "metadata": {
        "id": "XztP3BQO1f7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.init()"
      ],
      "metadata": {
        "id": "3CyGP4dD1qUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining neccesary settings\n",
        "\n",
        "#define list of algorithms\n",
        "full_set = ['DRF', 'GLM', 'XGBoost', 'GBM', 'DeepLearning', 'StackedEnsemble']\n",
        "\n",
        "dict_algos = {'Distributed_Random_Forest': 'DRF',\n",
        "              'Generalized_Linear_Model': 'GLM',\n",
        "              'XGBoost': 'XGBoost',\n",
        "              'Gradient_Boosting_Machine': 'GBM',\n",
        "              'Deep_Learning': 'DeepLearning',\n",
        "              'Stacked_Ensembles': 'StackedEnsemble'}\n",
        "\n",
        "#load ontology from file\n",
        "onto = get_ontology(\"OntologyEmpty.owl\").load()\n",
        "\n",
        "#meta-features stored in ontology\n",
        "dict_features = {\n",
        "    'BinaryClass' : onto.BinaryClass,\n",
        "    'NoBinaryClass' : onto.NoBinaryClass,\n",
        "    'StringClass' : onto.StringClass,\n",
        "    'NoStringClass' : onto.NoStringClass,\n",
        "    'UnaryAttibutes' : onto.UnaryAttibutes,\n",
        "    'NoUnaryAttibutes' : onto.NoUnaryAttibutes,\n",
        "    'ManyFeatures' : onto.ManyFeatures,\n",
        "    'FewFeatures' : onto.FewFeatures,\n",
        "    'NoManyFeatures' : onto.FewFeatures,\n",
        "    'NoFewFeatures' : onto.ManyFeatures,\n",
        "    'ManyInstances' : onto.ManyInstances,\n",
        "    'FewInstances' : onto.FewInstances,\n",
        "    'NoManyInstances' : onto.FewInstances,\n",
        "    'NoFewInstances' : onto.ManyInstances,\n",
        "    'BinaryAttributes' : onto.BinaryAttributes,\n",
        "    'NoBinaryAttributes' : onto.NoBinaryAttributes,\n",
        "    'NumericAttributes' : onto.NumericAttributes,\n",
        "    'NoNumericAttributes' : onto.NoNumericAttributes,\n",
        "    'NominalAttributes' : onto.NominalAttributes,\n",
        "    'NoNominalAttributes' : onto.NoNominalAttributes,\n",
        "    'StringAttributes' : onto.StringAttributes,\n",
        "    'NoStringAttributes' : onto.NoStringAttributes,\n",
        "    'MissingValues' : onto.MissingValues,\n",
        "    'NoMissingValues' : onto.NoMissingValues,\n",
        "    'NumericClass' : onto.NumericClass,\n",
        "    'NoNumericClass' : onto.NoNumericClass\n",
        "    }\n",
        "\n",
        "#create empty frame for results\n",
        "results = pd.DataFrame(columns=[\"Dataset\", \"AutoML library\",\t\"Limit\",\t\"Num. DataSets\", \"Data characteristic\",\t\"Selected algorithm\",\t\"Accuracy\", \"Precision\", \"Recall\", \"F-measure\",\t\"AUC\", \"Time elapsed\"])"
      ],
      "metadata": {
        "id": "601c6Wvqdah2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for quering ontology with specific meta-feature\n",
        "def queryOntology(num, data_char):\n",
        "  ontologyName = \"ontology-\"+str(num)+\"-h2o.owl\"\n",
        "  onto = get_ontology(ontologyName).load()\n",
        "\n",
        "  # querying ontology\n",
        "  list_algos = list()\n",
        "  for cls in list(onto.H2OAlgorithm.subclasses()):\n",
        "    if (dict_features[data_char] in cls.suitableFor):\n",
        "      print(cls.name)\n",
        "      list_algos.append(dict_algos[cls.name])\n",
        "  return list_algos"
      ],
      "metadata": {
        "id": "FB3pR6Hchtbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset and extract its meta-features\n",
        "#firstly all features are false\n",
        "features = pd.Series(data=[False] * 24, index=['ManyInstances', 'FewInstances', 'ManyFeatures', 'FewFeatures',\n",
        "       'BinaryClass', 'DateClass', 'MissingClassValues', 'NominalClass',\n",
        "       'NumericClass', 'NoClass', 'UnaryClass', 'EmptyNominalClass',\n",
        "       'StringClass', 'RelationalClass', 'OnlyMulti-InstanceData',\n",
        "       'BinaryAttributes', 'DateAttributes', 'EmptyNominalAttributes',\n",
        "       'MissingValues', 'NominalAttributes', 'NumericAttributes',\n",
        "       'UnaryAttibutes', 'RelationalAttributes', 'StringAttributes'])\n",
        "\n",
        "#load dataset from OpenML by id\n",
        "opml = fetch_openml(data_id=41169, as_frame=True, parser='auto')\n",
        "\n",
        "#data for features extraction\n",
        "X = opml.data\n",
        "y = opml.target\n",
        "name = opml.details['name']\n",
        "\n",
        "#extracting meta-features\n",
        "#extracting the size of the dataset\n",
        "shape = X.shape\n",
        "n_instances = shape[0]\n",
        "n_features = shape[1]\n",
        "n_target_values = len(y.unique())\n",
        "numeric_data = X.select_dtypes(include=[np.number])\n",
        "not_numeric_data = X.select_dtypes(exclude=[np.number])\n",
        "category_data = X.select_dtypes(include=['category'])\n",
        "\n",
        "#extracting information about the target class\n",
        "if n_target_values == 2:\n",
        "  binary_class = True\n",
        "  features['BinaryClass'] = True\n",
        "  print(\"Binary\")\n",
        "else:\n",
        "  binary_class = False\n",
        "  print(\"MultiClass\")\n",
        "\n",
        "if y.str.isnumeric().any():\n",
        "  features['NumericClass'] = True\n",
        "  string_class = False\n",
        "  print(\"No string class\")\n",
        "else:\n",
        "  string_class = True\n",
        "  features['StringClass'] = True\n",
        "  print(\"String class\")\n",
        "\n",
        "if y.dtype=='category':\n",
        "  features['NominalClass'] = True\n",
        "\n",
        "if n_instances > 3200:\n",
        "  many_instances = True\n",
        "  features['ManyInstances'] = True\n",
        "  print(\"Many instances\")\n",
        "else:\n",
        "  many_instances = False\n",
        "  features['FewInstances'] = True\n",
        "  print(\"Few instances\")\n",
        "\n",
        "if n_features > 100:\n",
        "  print(\"Many features\")\n",
        "else:\n",
        "  features['FewFeatures'] = True\n",
        "  print(\"Few features\")\n",
        "\n",
        "#extracting information about dataset attributes\n",
        "if numeric_data.shape[1] > 0:\n",
        "  features['NumericAttributes'] = True\n",
        "\n",
        "if category_data.shape[1] > 0:\n",
        "  features['NominalAttributes'] = True\n",
        "\n",
        "binary_attributes = False\n",
        "string_attributes = False\n",
        "missing_values = False\n",
        "\n",
        "for fname in opml.feature_names:\n",
        "  if len(X[fname].unique())==2: # and not binary_attributes:\n",
        "    binary_attributes = True\n",
        "    features['BinaryAttributes'] = True\n",
        "\n",
        "  if len(X[fname].unique())==1:\n",
        "    features['UnaryAttributes'] = True\n",
        "\n",
        "  if X[fname].isna().sum() > 0:\n",
        "    missing_values = True\n",
        "    features['MissingValues'] = True\n",
        "\n",
        "  if not pd.api.types.is_numeric_dtype(X[fname]):\n",
        "    string_attributes = True\n",
        "    features['StringAttributes'] = True\n",
        "\n",
        "if binary_attributes:\n",
        "  print(\"Binary attributes\")\n",
        "else:\n",
        "  print(\"No binary attributes\")\n",
        "if missing_values:\n",
        "  print(\"Missing values\")\n",
        "else:\n",
        "  print(\"No missing values\")\n",
        "if string_attributes:\n",
        "  print(\"String attributes\")\n",
        "else:\n",
        "  print(\"No string attributes\")\n",
        "\n",
        "x=opml.feature_names\n",
        "y=opml.target.name\n",
        "frame = h2o.H2OFrame(opml.frame)\n",
        "train, test = frame.split_frame(ratios=[.75])\n",
        "\n",
        "if train[y].isnumeric():\n",
        "  train[y] = train[y].asfactor()\n",
        "  test[y] = test[y].asfactor()\n",
        "  print(\"convert numeric target to categorial\")\n",
        "else:\n",
        "  print(\"target remained the same\")"
      ],
      "metadata": {
        "id": "F_bAqFYc2Iy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performing AutoML search for model using different constrains\n",
        "\n",
        "cost_lim = 0.70 #threshold for the early stopping (misclassification)\n",
        "num_ds = 35     #number of datasets used fore ontology creation\n",
        "runtime = 900   #amount of time allocated for the search (in seconds)\n",
        "d_char = \"NoBinaryAttributes\" #attribute to search into ontology\n",
        "\n",
        "for i in range(0,5):\n",
        "# 0 - search with time constrain\n",
        "# 1 - search with time constrain and early stopping\n",
        "# >1 - search with time constrain, early stopping and use of ontology\n",
        "\n",
        "  start_time = time.time()\n",
        "  num = results.shape[0]\n",
        "\n",
        "  #AutoML settings\n",
        "  if i==0:\n",
        "    data_char = \"No characteristics\"\n",
        "    limits = \"No limits\"\n",
        "    automl = h2o.automl.H2OAutoML(max_runtime_secs=runtime)\n",
        "\n",
        "  if i==1:\n",
        "    data_char = \"No characteristics\"\n",
        "    limits = \"misclas=\" + str(cost_lim)\n",
        "\n",
        "    automl = h2o.automl.H2OAutoML(\n",
        "    stopping_metric = \"misclassification\",\n",
        "    stopping_rounds = 1,\n",
        "    stopping_tolerance = cost_lim,\n",
        "    max_runtime_secs=runtime)\n",
        "\n",
        "  if i>1:\n",
        "    results.at[num, \"Num. DataSets\"] = num_ds\n",
        "    data_char = d_char\n",
        "    limits = \"misclas=\" + str(cost_lim)\n",
        "    list_algos = queryOntology(num_ds, data_char)\n",
        "\n",
        "    automl = h2o.automl.H2OAutoML(\n",
        "    stopping_metric = \"misclassification\",\n",
        "    stopping_rounds = 1,\n",
        "    stopping_tolerance = cost_lim,\n",
        "    include_algos=list_algos,\n",
        "    max_runtime_secs=runtime)\n",
        "\n",
        "  print(\"searching for model\")\n",
        "  automl.train(x=x, y=y, training_frame=train)\n",
        "  print(\"model found\")\n",
        "  elapsed = time.time() - start_time\n",
        "  print(\"elapsed: \", elapsed)\n",
        "\n",
        "  #info about found models\n",
        "  print(\"leaderboard\")\n",
        "  print(\"leaderboard:\", h2o.automl.get_leaderboard(automl, extra_columns = \"ALL\"))\n",
        "\n",
        "  algo = automl.leader.key\n",
        "\n",
        "  if binary_class: #metrics for binary classifications\n",
        "    perf = automl.leader.model_performance(test)\n",
        "    accuracy = perf.accuracy()[0][1]\n",
        "    precision = perf.precision()[0][1]\n",
        "    recall = perf.recall()[0][1]\n",
        "    f1 = perf.F1()[0][1]\n",
        "    auc = perf.auc()\n",
        "  else:\n",
        "    y_test = test[y].as_data_frame()\n",
        "    y_pred_0 = automl.leader.predict(test)  #calculate predictions\n",
        "    y_pred = y_pred_0['predict'].as_data_frame() #take from table only predictions\n",
        "    accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
        "    precision = sklearn.metrics.precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    recall = sklearn.metrics.recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    f1 = sklearn.metrics.f1_score(y_test, y_pred, average='macro')\n",
        "    preds_0 = y_pred_0.as_data_frame() #convert H2OFrame to DataFrame\n",
        "    preds = preds_0.drop('predict', axis=1)  #remove name of classes (first column)\n",
        "    y_test_p = y_test[y]  #convert DataFrame to Series\n",
        "    auc = sklearn.metrics.roc_auc_score(y_test_p, preds, multi_class='ovr')\n",
        "\n",
        "  print(\"algo: \",algo)\n",
        "  print(\"Accuracy\", accuracy)\n",
        "  print(\"Precision\", precision)\n",
        "  print(\"Recall\", recall)\n",
        "  print(\"F-measure\", f1)\n",
        "  print(\"AUC\", auc)\n",
        "\n",
        "  results.at[num,'Dataset'] = name\n",
        "  results.at[num,'AutoML library'] = \"H2O\"\n",
        "  results.at[num,'Limit'] = limits\n",
        "  results.at[num,'Data characteristic'] = data_char\n",
        "  results.at[num,'Selected algorithm'] = algo\n",
        "  results.at[num,'Accuracy'] = accuracy\n",
        "  results.at[num,'Precision'] = precision\n",
        "  results.at[num,'Recall'] = recall\n",
        "  results.at[num,'F-measure'] = f1\n",
        "  results.at[num,'AUC'] = auc\n",
        "  results.at[num,'Time elapsed'] = elapsed"
      ],
      "metadata": {
        "id": "FhrJiS0ziSh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results.shape[0])\n",
        "print(results[['Dataset', 'Num. DataSets', 'Accuracy', 'AUC','Time elapsed']])\n",
        "results.to_excel('Experiments-h2o.xlsx')"
      ],
      "metadata": {
        "id": "U7-tnCJnoO0y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
